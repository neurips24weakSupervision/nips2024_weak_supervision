{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb2db34",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50590db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38239cd8",
   "metadata": {},
   "source": [
    "# Specify path and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3dfc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace with your path here\n",
    "path_name = \"final_evaluation/texture_final_2\" #path where outputs of \"inference.py\" are stored\n",
    "path_name_properties = \"evaluation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643097b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load outputs generated by inference.py\n",
    "all_images = np.load(path_name+\"/all_images.npy\")\n",
    "all_masks = np.load(path_name+\"/all_masks.npy\")\n",
    "all_recons = np.load(path_name+\"/all_recons.npy\")\n",
    "all_predictions = np.load(path_name+\"/all_predictions.npy\")\n",
    "all_masks_predicted = np.load(path_name+\"/all_masks_predicted.npy\")\n",
    "all_slots = np.load(path_name+\"/all_slots.npy\")\n",
    "all_positions = np.load(path_name+\"/all_positions.npy\")\n",
    "all_sizes = np.load(path_name+\"/all_sizes.npy\")\n",
    "all_masks_predicted = np.transpose(all_masks_predicted,[0,1,3,4,2,5]).reshape(156,32,128,128,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f6aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_properties = np.load(path_name_properties+\"/ground_truth_properties.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ec334a",
   "metadata": {},
   "source": [
    "# Bind Slots to Ground-Truth Objects via Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c201019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_slots(mask_pred, mask_ref):\n",
    "    mask_ref = mask_ref.astype(int).reshape(128,128).flatten() #transform 2D ground-truth masks to a 1D integer list\n",
    "    mask_pred = mask_pred.argmax(axis=-1).flatten() #transform softmaxed predicted masks to a 1D integer list\n",
    "    classes = np.unique(mask_ref) #get all classes present in the ground-truth objects.\n",
    "    pairs = [] #safe (ground-truth mask, predicted mask) pairs\n",
    "    for j in classes: #iterate over all classes\n",
    "        index_mask_predicted, overlap_percent = find_largest_overlap(mask_pred,mask_ref,j)\n",
    "        if overlap_percent < 0.35: #check that slot is not a background slot \n",
    "            return []\n",
    "        if j != 0: #first slot is the background, do not include it\n",
    "            pairs.append((j-1, index_mask_predicted))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def find_largest_overlap(mask_pred, mask_ref, j):\n",
    "    mask_positions = np.array(mask_ref) == j #boolean array where ground-truth mask is\n",
    "    countsBefore = np.bincount(mask_pred) #store how many pixels belong to each predicted slot \n",
    "    mask_pred = mask_pred[mask_positions] #consider only pixels where ground-truth mask is\n",
    "    counts = np.bincount(mask_pred) #get counts of overlapping pixels\n",
    "    index_max_overlap = np.argmax(counts) #get index of largest overlapping slot\n",
    "    index_max_overlap_count = counts[index_max_overlap] #get count of largest overlapping slot\n",
    "    overlap_percent = index_max_overlap_count / len(mask_pred) #check that slot is not a background slot (mask of slot is now allowed to be more than 3 times bigger than the real object)\n",
    "    return index_max_overlap, overlap_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ebf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "binded_slots = []\n",
    "binded_properties = []\n",
    "for i in range(156):\n",
    "    for j in range(32):\n",
    "        pairs = match_slots(all_masks_predicted[i][j],all_masks[i][j])\n",
    "        for refs, preds in pairs:\n",
    "            binded_properties.append(all_properties[i][j][refs])\n",
    "            #concat slot representations with its position invariant parameters\n",
    "            concat_slots = np.concatenate((all_slots[i][j][preds] , all_positions[i][j][preds]), axis = -1)\n",
    "            concat_slots = np.concatenate((concat_slots, all_sizes[i][j][preds]), axis = -1)\n",
    "            binded_slots.append(concat_slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278c48ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#safe pairs - these can further be used for computing disentanglement metrics, found at: https://github.com/google-research/disentanglement_lib\n",
    "np.save(path_name + \"/binded_properties.npy\",np.array(all_properties))\n",
    "np.save(path_name + \"/binded_slots.npy\",np.array(all_slots))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532acf22",
   "metadata": {},
   "source": [
    "# Predict Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35443529",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs to model: Binded (Slot, Property)-pairs\n",
    "X = all_slots\n",
    "y = all_properties\n",
    "\n",
    "# Validate the shape of the loaded data\n",
    "print(f\"Shape of X: {X.shape}\")  \n",
    "print(f\"Shape of y: {y.shape}\")\n",
    "\n",
    "# Split the one-hot encoded labels into shape, size, and material - do not consider position\n",
    "y_size = y[:, 3:6]\n",
    "y_material = y[:, 6:71-5]\n",
    "y_shape = y[:, 71-5:70]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train_shape, y_test_shape = train_test_split(X, y_shape, test_size=0.2, random_state=42)\n",
    "_, _, y_train_size, y_test_size = train_test_split(X, y_size, test_size=0.2, random_state=42)\n",
    "_, _, y_train_material, y_test_material = train_test_split(X, y_material, test_size=0.2, random_state=42)\n",
    "\n",
    "# Neural network architecture - here: only linear layer\n",
    "input_layer = Input(shape=(X.shape[1],))\n",
    "#x = Dense(128, activation='relu')(input_layer)\n",
    "#x = Dense(128, activation='relu')(x)\n",
    "\n",
    "# Output layers\n",
    "output_shape = Dense(4, activation='softmax', name='shape')(input_layer)\n",
    "output_size = Dense(3, activation='softmax', name='size')(input_layer)\n",
    "output_material = Dense(60, activation='softmax', name='material')(input_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=[output_shape, output_size, output_material])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss={'shape': 'categorical_crossentropy',\n",
    "                    'size': 'categorical_crossentropy',\n",
    "                    'material': 'categorical_crossentropy'},\n",
    "              metrics={'shape': 'accuracy', 'size': 'accuracy', 'material': 'accuracy'})\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, [y_train_shape, y_train_size, y_train_material],\n",
    "                    epochs=500,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = model.evaluate(X_test, [y_test_shape, y_test_size, y_test_material])\n",
    "print(f\"Test Results - Shape Loss: {eval_results[1]}, Size Loss: {eval_results[2]}, Material Loss: {eval_results[3]}\")\n",
    "print(f\"Test Results - Shape Accuracy: {eval_results[4]}, Size Accuracy: {eval_results[5]}, Material Accuracy: {eval_results[6]}\")\n",
    "# Calculate the overall accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_shape = np.argmax(y_pred[0], axis=1)\n",
    "y_pred_size = np.argmax(y_pred[1], axis=1)\n",
    "y_pred_material = np.argmax(y_pred[2], axis=1)\n",
    "\n",
    "y_true_shape = np.argmax(y_test_shape, axis=1)\n",
    "y_true_size = np.argmax(y_test_size, axis=1)\n",
    "y_true_material = np.argmax(y_test_material, axis=1)\n",
    "\n",
    "# Check if all properties are correctly predicted\n",
    "correct_predictions = np.all([y_pred_shape == y_true_shape,\n",
    "                              y_pred_size == y_true_size,\n",
    "                              y_pred_material == y_true_material], axis=0)\n",
    "\n",
    "# Overall accuracy\n",
    "overall_accuracy = np.mean(correct_predictions)\n",
    "print(f\"Overall Accuracy (all properties correct): {overall_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
